{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from typing import Tuple,List\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse,unbatch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.distributions import Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conditional_rate_matching.data.graph_dataloaders_config import CommunitySmallGConfig\n",
    "from conditional_rate_matching.data.graph_dataloaders_config import GraphDataloaderGeometricConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_graph_lists(graph_data_config:GraphDataloaderGeometricConfig)->Tuple[List[nx.Graph]]:\n",
    "    \"\"\"\n",
    "    parameters\n",
    "    ----------\n",
    "\n",
    "    return\n",
    "    ------\n",
    "        Tuple[List[nx.Graph]]: train_graph_list, test_graph_list\n",
    "    \"\"\"\n",
    "    data_dir = graph_data_config.data_dir\n",
    "    file_name = graph_data_config.dataset_name\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    with open(file_path + '.pkl', 'rb') as f:\n",
    "        graph_list = pickle.load(f)\n",
    "    test_size = int(graph_data_config.test_split * len(graph_list))\n",
    "    train_graph_list, test_graph_list = graph_list[test_size:], graph_list[:test_size]\n",
    "    return train_graph_list, test_graph_list\n",
    "\n",
    "def create_geometric_dataset(train_graph_list:List[nx.Graph],test_graph_list:List[nx.Graph])->Tuple[List[Data]]:\n",
    "    \"\"\"\n",
    "    we take the list of networkx graph and create a torch_geometric dataset\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "        train_graph_list,test_graph_list\n",
    "    return\n",
    "    ------\n",
    "    train_dataset,test_dataset\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    max_train = max([graph.number_of_nodes() for graph in train_graph_list])\n",
    "    max_test = max([graph.number_of_nodes() for graph in test_graph_list])\n",
    "\n",
    "    max_num_nodes = max(max_train,max_test)\n",
    "    num_node_features = max_num_nodes\n",
    "\n",
    "    for graph in train_graph_list:\n",
    "        adj = nx.to_numpy_array(graph)\n",
    "        number_of_nodes = adj.shape[0]\n",
    "\n",
    "        padded_adj = np.zeros((max_num_nodes,max_num_nodes))\n",
    "        padded_adj[:number_of_nodes,:number_of_nodes] = adj\n",
    "\n",
    "        edge_index = dense_to_sparse(torch.Tensor(adj))[0]\n",
    "        nodes_attributes = torch.eye(max_num_nodes)\n",
    "        train_data.append(Data(x=nodes_attributes,edge_index=edge_index))\n",
    "\n",
    "    for graph in test_graph_list:\n",
    "        adj = nx.to_numpy_array(graph)\n",
    "        number_of_nodes = adj.shape[0]\n",
    "\n",
    "        padded_adj = np.zeros((max_num_nodes,max_num_nodes))\n",
    "        padded_adj[:number_of_nodes,:number_of_nodes] = adj\n",
    "\n",
    "        edge_index = dense_to_sparse(torch.Tensor(adj))[0]\n",
    "\n",
    "        nodes_attributes = torch.eye(max_num_nodes)\n",
    "        test_data.append(Data(x=nodes_attributes,edge_index=edge_index))\n",
    "    \n",
    "    return train_data,test_data,num_node_features\n",
    "\n",
    "class GraphGeometricDataloader:\n",
    "\n",
    "    def __init__(self,config:GraphDataloaderGeometricConfig):\n",
    "        self.config = config\n",
    "        train_graph_list, test_graph_list = read_graph_lists(config)\n",
    "        train_dataset,test_dataset,num_node_features = create_geometric_dataset(train_graph_list,test_graph_list)\n",
    "\n",
    "        self.num_node_features = num_node_features\n",
    "        self.config.dimensions = num_node_features\n",
    "        self.train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size)\n",
    "        self.test_dataloader = DataLoader(test_dataset,batch_size=config.batch_size)\n",
    "    \n",
    "    def train(self):\n",
    "        return self.train_dataloader\n",
    "    \n",
    "    def test(self):\n",
    "        return self.test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features,hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "\n",
    "\n",
    "from torch_geometric.utils import dense_to_sparse,unbatch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def sample_to_geometric(X,number_of_nodes=20):\n",
    "    \"\"\"\n",
    "    obtains a representation which is suuitable for GNNs defined wiith the torch_geometric library\n",
    "    \"\"\"\n",
    "    batch_size = X.shape[0]\n",
    "    adj = X[:,:,None].reshape(batch_size,number_of_nodes,number_of_nodes)\n",
    "    edge_index = dense_to_sparse(torch.Tensor(adj))[0]\n",
    "    nodes_attributes = torch.eye(number_of_nodes)\n",
    "    nodes_attributes = nodes_attributes.repeat((batch_size,1))\n",
    "    batch = torch.arange(batch_size).repeat_interleave(number_of_nodes)\n",
    "    return nodes_attributes,edge_index,batch\n",
    "\n",
    "class EmbedFC(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim):\n",
    "        super(EmbedFC, self).__init__()\n",
    "        '''\n",
    "        generic one layer FC NN for embedding things  \n",
    "        '''\n",
    "        self.input_dim = input_dim\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "class SimpleTemporalGCN(torch.nn.Module):\n",
    "    def __init__(self,num_nodes,num_node_features,hidden_channels,time_dimension=19):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.number_of_nodes = num_nodes\n",
    "        self.num_node_features = num_node_features\n",
    "        \n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.timeembed1 = EmbedFC(1, time_dimension)\n",
    "\n",
    "        self.edge_encoding_0 = Linear(2*hidden_channels,hidden_channels)\n",
    "        self.edge_encoding = Linear(hidden_channels+time_dimension,1)\n",
    "\n",
    "    def forward(self, X, time):\n",
    "        x,edge_index,batch = sample_to_geometric(X,number_of_nodes=self.number_of_nodes)\n",
    "        time_emb = self.timeembed1(time)\n",
    "\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # 2. Create outer concatenation for the edge encoding\n",
    "        x = torch.stack(unbatch(x,batch=batch),dim=0)\n",
    "        N = self.number_of_nodes\n",
    "\n",
    "        x_i = x.unsqueeze(2)  # Shape becomes (batch_size, N, 1, D)\n",
    "        x_j = x.unsqueeze(1)  # Shape becomes (batch_size, 1, N, D)\n",
    "        \n",
    "        # Concatenate the expanded tensors along the last dimension\n",
    "        x = torch.cat((x_i.expand(-1, -1, N, -1), x_j.expand(-1, N, -1, -1)), dim=-1)  # Shape becomes (batch_size, N, N, 2*D)\n",
    "        x = self.edge_encoding_0(x) # Shape becomes (batch_size,N,N,D)\n",
    "\n",
    "        # Expand time_emb to match the dimensions of B\n",
    "        time_emb = time_emb.unsqueeze(1).unsqueeze(2).expand(-1, N, N, -1)  # Shape becomes (batch_size, N, N, time_emd_dim)\n",
    "\n",
    "        # Concatenate time_emb_expanded to B along the last dimension\n",
    "        x = torch.cat((x, time_emb), dim=-1)  # Shape becomes (batch_size, N, N, D + time_emd_dim)\n",
    "        x = self.edge_encoding(x) # Shape becomes (batch_size, N, N, 1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[60, 20], edge_index=[2, 146], batch=[60], ptr=[4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "hidden_channels = 64\n",
    "time_encoding = 9\n",
    "number_of_nodes = 20\n",
    "\n",
    "graph_config = CommunitySmallGConfig(batch_size=batch_size)\n",
    "graph_dataloader = GraphGeometricDataloader(graph_config)\n",
    "model = GCN(20,graph_dataloader.num_node_features,hidden_channels=hidden_channels)\n",
    "\n",
    "batch = next(graph_dataloader.train().__iter__())\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "X = Bernoulli(torch.rand((number_of_nodes*number_of_nodes))).sample((batch_size,))\n",
    "time = torch.rand((batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 20, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X,time).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 20])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nodes_attributes,edge_index,batch \u001b[38;5;241m=\u001b[39m sample_to_geometric(\u001b[43mX\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "nodes_attributes,edge_index,batch = sample_to_geometric(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 20, 1])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.edge_encoding(output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 1, 64])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbatch(output,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 20])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_product = torch.einsum(\"bik,bjk->bij\",result,result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rate_matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
