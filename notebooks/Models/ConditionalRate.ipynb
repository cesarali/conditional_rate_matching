{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f26690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sympy\n",
    "from dataclasses import dataclass\n",
    "from torchvision import transforms\n",
    "from torch.optim.adam import Adam\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn.functional import softplus,softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ae632",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db533424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b58e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conditional_rate_matching.configs.config_files import ExperimentFiles\n",
    "from conditional_rate_matching.data.states_dataloaders import sample_categorical_from_dirichlet\n",
    "from graph_bridges.models.temporal_networks.embedding_utils import transformer_timestep_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2a81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "\n",
    "    # data\n",
    "    number_of_spins :int = 3\n",
    "    number_of_states :int = 4\n",
    "    sample_size :int = 200\n",
    "\n",
    "    dirichlet_alpha_0 :float = 0.1\n",
    "    dirichlet_alpha_1 :float = 100.\n",
    "\n",
    "    bernoulli_probability_0 :float = 0.2\n",
    "    bernoulli_probability_0 :float = 0.8\n",
    "\n",
    "    # process\n",
    "    gamma :float = .9\n",
    "\n",
    "    # model\n",
    "\n",
    "    # temporal network\n",
    "    time_embed_dim :int = 9\n",
    "    hidden_dim :int = 50\n",
    "\n",
    "    # rate\n",
    "    loss:str = \"classifier\" # classifier,naive\n",
    "    \n",
    "    # training\n",
    "    number_of_epochs = 1\n",
    "    learning_rate = 0.01\n",
    "    batch_size :int = 5\n",
    "    device = \"cuda:0\"\n",
    "\n",
    "    #pipeline\n",
    "    number_of_steps:int = 20\n",
    "    num_intermediates:int = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.num_intermediates = int(.5*self.number_of_steps)\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67853cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.distributions import Dirichlet\n",
    "import torch\n",
    "\n",
    "# Parameters\n",
    "dataset_0 = sample_categorical_from_dirichlet(probs=None,\n",
    "                                              alpha=config.dirichlet_alpha_0,\n",
    "                                              sample_size=config.sample_size,\n",
    "                                              dimension=config.number_of_spins,\n",
    "                                              number_of_states=config.number_of_states)\n",
    "tensordataset_0 = TensorDataset(dataset_0)\n",
    "dataloader_0 = DataLoader(tensordataset_0,batch_size=config.batch_size)\n",
    "\n",
    "dataset_1 = sample_categorical_from_dirichlet(probs=None,\n",
    "                                              alpha=config.dirichlet_alpha_1,\n",
    "                                              sample_size=183,\n",
    "                                              dimension=config.number_of_spins,\n",
    "                                              number_of_states=config.number_of_states)\n",
    "tensordataset_1 = TensorDataset(dataset_1)\n",
    "dataloader_1 = DataLoader(tensordataset_1,batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22fc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dataset_0 = len(tensordataset_0)\n",
    "size_dataset_1 = len(tensordataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1699a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_integral(gamma, t1, t0):\n",
    "    \"\"\"\n",
    "    Dummy integral for constant rate\n",
    "    \"\"\"\n",
    "    interval = t1 - t0\n",
    "    integral = gamma * interval\n",
    "    return integral\n",
    "\n",
    "def conditional_probability(config, x, x0, t, t0):\n",
    "    \"\"\"\n",
    "\n",
    "    \\begin{equation}\n",
    "    P(x(t) = i|x(t_0)) = \\frac{1}{s} + w_{t,t_0}\\left(-\\frac{1}{s} + \\delta_{i,x(t_0)}\\right)\n",
    "    \\end{equation}\n",
    "\n",
    "    \\begin{equation}\n",
    "    w_{t,t_0} = e^{-S \\int_{t_0}^{t} \\beta(r)dr}\n",
    "    \\end{equation}\n",
    "\n",
    "    \"\"\"\n",
    "    right_shape = lambda x: x if len(x.shape) == 3 else x[:, :, None]\n",
    "    right_time_size = lambda t: t if isinstance(t, torch.Tensor) else torch.full((x.size(0),), t)\n",
    "\n",
    "    t = right_time_size(t).to(x0.device)\n",
    "    t0 = right_time_size(t0).to(x0.device)\n",
    "\n",
    "    S = config.number_of_states\n",
    "    integral_t0 = beta_integral(config.gamma, t, t0)\n",
    "\n",
    "    w_t0 = torch.exp(-S * integral_t0)\n",
    "\n",
    "    x = right_shape(x)\n",
    "    x0 = right_shape(x0)\n",
    "\n",
    "    delta_x = (x == x0).float()\n",
    "    probability = 1. / S + w_t0[:, None, None] * ((-1. / S) + delta_x)\n",
    "\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a22c0",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(x(t) = i|x(t_0) = j) = \\frac{1}{s} + w_{t,t_0}\\left(-\\frac{1}{s} + \\delta_{i,x(t_0)=j}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "w_{t,t_0} = e^{-S \\int_{t_0}^{t} \\beta(r)dr}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c62a518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_transition_probability(config, x, x1, x0, t):\n",
    "    \"\"\"\n",
    "    \\begin{equation}\n",
    "    P(x_t=x|x_0,x_1) = \\frac{p(x_1|x_t=x) p(x_t = x|x_0)}{p(x_1|x_0)}\n",
    "    \\end{equation}\n",
    "    \"\"\"\n",
    "\n",
    "    P_x_to_x1 = conditional_probability(config, x1, x, t=1., t0=t)\n",
    "    P_x0_to_x = conditional_probability(config, x, x0, t=t, t0=0.)\n",
    "    P_x0_to_x1 = conditional_probability(config, x1, x0, t=1., t0=0.)\n",
    "\n",
    "    conditional_transition_probability = (P_x_to_x1 * P_x0_to_x) / P_x0_to_x1\n",
    "    return conditional_transition_probability\n",
    "\n",
    "def constant_rate(config, x, t):\n",
    "    right_time_size = lambda t: t if isinstance(t, torch.Tensor) else torch.full((x.size(0),), t)\n",
    "    t = right_time_size(t).to(x.device)\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    dimension = x.size(1)\n",
    "\n",
    "    assert batch_size == t.size(0)\n",
    "\n",
    "    rate_ = torch.full((batch_size, dimension, config.number_of_states),\n",
    "                       config.gamma)\n",
    "    return rate_\n",
    "\n",
    "def conditional_transition_rate(config, x, x1, t):\n",
    "    \"\"\"\n",
    "    \\begin{equation}\n",
    "    f_t(\\*x'|\\*x,\\*x_1) = \\frac{p(\\*x_1|x_t=\\*x')}{p(\\*x_1|x_t=\\*x)}f_t(\\*x'|\\*x)\n",
    "    \\end{equation}\n",
    "    \"\"\"\n",
    "    where_to_x = torch.arange(0, config.number_of_states)\n",
    "    where_to_x = where_to_x[None, None, :].repeat((x.size(0), config.number_of_spins, 1)).float()\n",
    "    where_to_x = where_to_x.to(x.device)\n",
    "\n",
    "    P_xp_to_x1 = conditional_probability(config, x1, where_to_x, t=1., t0=t)\n",
    "    P_x_to_x1 = conditional_probability(config, x1, x, t=1., t0=t)\n",
    "\n",
    "    forward_rate = constant_rate(config, x, t).to(x.device)\n",
    "    rate_transition = (P_xp_to_x1 / P_x_to_x1) * forward_rate\n",
    "\n",
    "    return rate_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37d247ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.softmax(conditional_transition_probability,dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d324240",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    P(x_t=x|x_0,x_1) = \\frac{p(x_1|x_t=x) p(x_t = x|x_0)}{p(x_1|x_0)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0bc751",
   "metadata": {},
   "source": [
    "$\\newcommand{\\*}[1]{\\bar{\\mathbf{#1}}}$\n",
    "\n",
    "\\begin{equation}\n",
    "f_t(\\*x'|\\*x,\\*x_1) = \\frac{p(\\*x_1|x_t=\\*x')}{p(\\*x_1|x_t=\\*x)}f_t(\\*x'|\\*x)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c21e52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_pair_x0_x1(batch_1,batch_0):\n",
    "    x_0 = batch_0[0]\n",
    "    x_1 = batch_1[0]\n",
    "    \n",
    "    batch_size_0 = x_0.size(0)\n",
    "    batch_size_1 = x_1.size(0)\n",
    "    \n",
    "    batch_size = min(batch_size_0,batch_size_1)\n",
    "    \n",
    "    x_0 = x_0[:batch_size,:]\n",
    "    x_1 = x_1[:batch_size,:]\n",
    "    \n",
    "    return x_1,x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6abe1a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#sample x from z\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m transition_logits \u001b[38;5;241m=\u001b[39m \u001b[43mconditional_transition_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_to_go\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m transition_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(transition_logits,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     38\u001b[0m sampled_x \u001b[38;5;241m=\u001b[39m Categorical(transition_probs)\u001b[38;5;241m.\u001b[39msample()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m, in \u001b[0;36mconditional_transition_probability\u001b[1;34m(config, x, x1, x0, t)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconditional_transition_probability\u001b[39m(config, x, x1, x0, t):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    \\begin{equation}\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    P(x_t=x|x_0,x_1) = \\frac{p(x_1|x_t=x) p(x_t = x|x_0)}{p(x_1|x_0)}\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \\end{equation}\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     P_x_to_x1 \u001b[38;5;241m=\u001b[39m \u001b[43mconditional_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     P_x0_to_x \u001b[38;5;241m=\u001b[39m conditional_probability(config, x, x0, t\u001b[38;5;241m=\u001b[39mt, t0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m)\n\u001b[0;32m     10\u001b[0m     P_x0_to_x1 \u001b[38;5;241m=\u001b[39m conditional_probability(config, x1, x0, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m, t0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m, in \u001b[0;36mconditional_probability\u001b[1;34m(config, x, x0, t, t0)\u001b[0m\n\u001b[0;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m right_shape(x)\n\u001b[0;32m     33\u001b[0m x0 \u001b[38;5;241m=\u001b[39m right_shape(x0)\n\u001b[1;32m---> 35\u001b[0m delta_x \u001b[38;5;241m=\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     36\u001b[0m probability \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m S \u001b[38;5;241m+\u001b[39m w_t0[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m ((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m/\u001b[39m S) \u001b[38;5;241m+\u001b[39m delta_x)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probability\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "x_to_go = torch.arange(0,config.number_of_states)\n",
    "x_to_go = x_to_go[None,None,:].repeat((config.batch_size,config.number_of_spins,1)).float()\n",
    "x_to_go = x_to_go.to(device)\n",
    "\n",
    "if config.loss == \"naive\":\n",
    "    model = ConditionalBackwardRate(config,device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "elif config.loss == \"classifier\":\n",
    "    model = ClassificationBackwardRate(config, device).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# initialize\n",
    "experiment_files = ExperimentFiles(experiment_name=\"crm\",\n",
    "                                   experiment_type=\"dirichlet\",\n",
    "                                   experiment_indentifier=\"test2\",\n",
    "                                   delete=True)\n",
    "experiment_files.create_directories()\n",
    "writer = SummaryWriter(experiment_files.tensorboard_path)\n",
    "optimizer = Adam(model.parameters(),lr=config.learning_rate)\n",
    "\n",
    "number_of_training_steps = 0\n",
    "for epoch in range(config.number_of_epochs):\n",
    "    for batch_1, batch_0 in zip(dataloader_1, dataloader_0):\n",
    "        \n",
    "        #data pair and time sample\n",
    "        x_1,x_0 = uniform_pair_x0_x1(batch_1,batch_0)\n",
    "        x_0 = x_0.float().to(device)\n",
    "        x_1 = x_1.float().to(device)\n",
    "        \n",
    "        batch_size = x_0.size(0)\n",
    "        time = torch.randn(batch_size).to(device)\n",
    "        \n",
    "        #sample x from z\n",
    "        transition_logits = conditional_transition_probability(config,x_to_go,x_1,x_0,time)\n",
    "        transition_probs = torch.softmax(transition_logits,dim=-1)\n",
    "        sampled_x = Categorical(transition_probs).sample().to(device)\n",
    "        \n",
    "        # conditional rate\n",
    "        if config.loss == \"naive\":\n",
    "            conditional_rate = conditional_transition_rate(config,sampled_x,x_1,time)\n",
    "            nn.so\n",
    "            model_rate = model(sampled_x,time)\n",
    "            loss = loss_fn(model_rate,conditional_rate)\n",
    "        elif config.loss == \"classifier\":\n",
    "            model_classification = model(x_1,time)                        \n",
    "            loss = loss_fn(model_classification.view(-1, config.number_of_states),\n",
    "                           sampled_x.view(-1))\n",
    "        \n",
    "        writer.add_scalar('training loss', loss.item(), number_of_training_steps)\n",
    "\n",
    "        # optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        number_of_training_steps += 1\n",
    "        \n",
    "        if number_of_training_steps % 100 == 0:\n",
    "            print(f\"loss {round(loss.item(),2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3517fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = ClassificationBackwardRate(config,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5df9f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7164,  0.1773, -0.3872,  0.8108],\n",
       "         [-0.6507, -0.4333, -1.2023, -0.7058],\n",
       "         [ 0.4041,  0.1171, -0.3459, -0.8481]],\n",
       "\n",
       "        [[-0.2368, -0.0823,  0.0034,  0.7070],\n",
       "         [-0.6131,  0.2125, -0.1449, -0.3256],\n",
       "         [ 0.6285,  0.3368, -1.2210, -0.6104]],\n",
       "\n",
       "        [[-0.5464, -0.1911, -1.0401,  0.7035],\n",
       "         [-0.8621, -0.1124, -0.7936, -1.1791],\n",
       "         [ 0.8389, -0.4177, -0.7438, -0.8912]],\n",
       "\n",
       "        [[-1.9241, -0.3258, -1.1273,  0.9582],\n",
       "         [-0.8725, -0.0349, -0.7608, -1.3455],\n",
       "         [ 0.5610,  0.3760, -0.7450, -1.1535]],\n",
       "\n",
       "        [[-1.2245,  0.3802, -0.1008,  0.5919],\n",
       "         [-0.5836, -0.4689, -1.1827, -0.2795],\n",
       "         [ 0.1145,  0.1531, -0.1293, -0.4495]]], device='cuda:0',\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(x_1, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21807e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92391360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationBackwardRate(nn.Module):\n",
    "    \n",
    "    def __init__(self,config,device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.S = config.number_of_states\n",
    "        self.D = config.number_of_spins\n",
    "        self.time_embed_dim = config.time_embed_dim\n",
    "        self.hidden_layer = config.hidden_dim\n",
    "        self.dimension = self.D\n",
    "        self.num_states = self.S\n",
    "        \n",
    "        self.expected_data_shape = [config.number_of_spins]\n",
    "        self.define_deep_models()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def define_deep_models(self):\n",
    "        self.f1 = nn.Linear(self.dimension, self.hidden_layer)\n",
    "        self.f2 = nn.Linear(self.hidden_layer + self.time_embed_dim, self.dimension * self.num_states)\n",
    "        \n",
    "        #self.f1 = nn.Linear(self.dimension, self.hidden_layer)\n",
    "        #self.f2 = nn.Linear(self.hidden_layer + self.time_embed_dim, self.dimension * self.num_states)\n",
    "        \n",
    "    def to_go(self,x,t):\n",
    "        x_to_go = torch.arange(0,self.S)\n",
    "        x_to_go = x_to_go[None,None,:].repeat((batch_size,self.D,1)).float()\n",
    "        x_to_go = x_to_go.to(device)\n",
    "        return x_to_go\n",
    "        \n",
    "    def classify(self,x,times):\n",
    "        batch_size = x.shape[0]\n",
    "        time_embbedings = transformer_timestep_embedding(times,\n",
    "                                                         embedding_dim=self.time_embed_dim)\n",
    "\n",
    "        step_one = self.f1(x)\n",
    "        step_two = torch.concat([step_one, time_embbedings], dim=1)\n",
    "        rate_logits = self.f2(step_two)\n",
    "        rate_logits = rate_logits.reshape(batch_size,self.dimension,self.num_states)\n",
    "\n",
    "        return rate_logits\n",
    "\n",
    "    def forward(self,x,t):\n",
    "        right_shape = lambda x: x if len(x.shape) == 3 else x[:, :, None]\n",
    "        right_time_size = lambda t: t if isinstance(t, torch.Tensor) else torch.full((x.size(0),), t).to(x.device)    \n",
    "    \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        w_1t = beta_integral(config.gamma, right_time_size(1.), right_time_size(t))\n",
    "        A = 1.\n",
    "        B = (w_1t*self.S)/(1.-w_1t)\n",
    "        C = w_1t \n",
    "        \n",
    "        x_to_go = self.to_go(x,t)\n",
    "        x_to_go = x_to_go.view((batch_size*self.S,self.D))\n",
    "        rate_logits = self.classify(x,time)  \n",
    "        return rate_logits\n",
    "    \n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.f1.weight)\n",
    "        nn.init.xavier_uniform_(self.f2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22dafb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalBackwardRate(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,config,device):\n",
    "        super().__init__()\n",
    "        self.expected_data_shape = [config.number_of_spins]\n",
    "        \n",
    "        self.temporal_network = TemporalMLP(dimensions=config.number_of_spins,\n",
    "                                       number_of_states=config.number_of_states,\n",
    "                                       time_embed_dim=config.time_embed_dim,\n",
    "                                       hidden_dim=config.hidden_dim,\n",
    "                                       device=device).to(device)\n",
    "        \n",
    "        #self.logits_to_rates = nn.Linear(self.temporal_network_output_size,)\n",
    "        \n",
    "    def forward(self,x,time):\n",
    "        batch_size = x.size(0)\n",
    "        #================================\n",
    "        #\n",
    "        expected_data_shape_ = torch.Size([batch_size] + self.expected_data_shape)\n",
    "        \n",
    "        temporal_network_logits = self.temporal_network(x,time)\n",
    "        rates_ = softplus(temporal_network_logits)\n",
    "        \n",
    "        return rates_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15639e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalMLP(nn.Module):\n",
    "\n",
    "    def __init__(self,dimensions,number_of_states,time_embed_dim,hidden_dim,device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_embed_dim = time_embed_dim\n",
    "        self.hidden_layer = hidden_dim\n",
    "        self.num_states = number_of_states\n",
    "        self.dimension = dimensions    \n",
    "        self.expected_output_shape = [self.dimension,self.num_states]\n",
    "    \n",
    "        self.define_deep_models()\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.device = device\n",
    "        self.to(self.device)\n",
    "        \n",
    "\n",
    "    def define_deep_models(self):\n",
    "        # layers\n",
    "        self.f1 = nn.Linear(self.dimension, self.hidden_layer)\n",
    "        self.f2 = nn.Linear(self.hidden_layer + self.time_embed_dim, self.dimension * self.num_states)\n",
    "\n",
    "    def forward(self,x,times):\n",
    "        batch_size = x.shape[0]\n",
    "        time_embbedings = transformer_timestep_embedding(times,\n",
    "                                                         embedding_dim=self.time_embed_dim)\n",
    "\n",
    "        step_one = self.f1(x)\n",
    "        step_two = torch.concat([step_one, time_embbedings], dim=1)\n",
    "        rate_logits = self.f2(step_two)\n",
    "        rate_logits = rate_logits.reshape(batch_size,self.dimension,self.num_states)\n",
    "\n",
    "        return rate_logits\n",
    "\n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.f1.weight)\n",
    "        nn.init.xavier_uniform_(self.f2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cebf0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3c95d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
