{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "add to image_dataloader_config.py\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class DistortedNISTLoaderConfig:\n",
    "    name:str = \"DistortedNISTLoader\"\n",
    "    dataset_name:str = \"mnist\" # emnist, fashion, mnist\n",
    "    batch_size: int= 23\n",
    "    data_dir:str = image_data_path\n",
    "    \n",
    "    distortion: str = 'noise' # noise, swirl, pixelate, half_mask\n",
    "    distortion_level: float = 0.4  # 0.4, 5, 0.7, None\n",
    "    \n",
    "    max_node_num: int = None\n",
    "    max_feat_num: int = None\n",
    "\n",
    "    dimensions: int = None\n",
    "    vocab_size: int = 2\n",
    "    unet_resize: bool = False\n",
    "\n",
    "    pepper_threshold: float = 0.5\n",
    "    flatten: bool = True\n",
    "    as_image: bool = False\n",
    "\n",
    "    max_training_size:int = None\n",
    "    max_test_size:int = None\n",
    "\n",
    "    total_data_size: int = None\n",
    "    training_size: int = None\n",
    "    test_size: int = None\n",
    "    test_split: float = None\n",
    "\n",
    "    temporal_net_expected_shape : List[int] = None\n",
    "    data_min_max: List[float] = field(default_factory=lambda:[0.,1.])\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.dimensions, self.temporal_net_expected_shape = self.expected_shape(self.as_image,self.flatten,self.unet_resize)\n",
    "        self.number_of_nodes = self.max_node_num\n",
    "        self.number_of_labels = NUMBER_OF_LABELS[self.dataset_name]\n",
    "\n",
    "    def expected_shape(self,as_image,flatten,unet=False):\n",
    "        if as_image:\n",
    "            if flatten:\n",
    "                shape = [1,1,784]\n",
    "                dimensions = 784\n",
    "            else:\n",
    "                if unet:\n",
    "                    shape = [1, 32, 32]\n",
    "                    dimensions = 1024\n",
    "                else:\n",
    "                    shape = [1, 28, 28]\n",
    "                    dimensions = 784\n",
    "        else:\n",
    "            if flatten:\n",
    "                shape = [784]\n",
    "                dimensions = 784\n",
    "            else:\n",
    "                shape = [28,28]\n",
    "                dimensions = 784\n",
    "        return dimensions, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/df630/.conda/envs/conditional_rate_matching/lib/python3.10/site-packages/tqdm-4.66.1-py3.10.egg/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Add this to 'image_dataloaders.py'\n",
    "'''\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from conditional_rate_matching.data.transforms import SqueezeTransform\n",
    "from conditional_rate_matching.data.transforms import FlattenTransform\n",
    "from conditional_rate_matching.data.image_dataloader_config import DistortedNISTLoaderConfig\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from skimage.transform import swirl\n",
    "\n",
    "\n",
    "def get_conditional_data(config: DistortedNISTLoaderConfig):\n",
    "    data_= config.dataset_name\n",
    "    threshold = config.pepper_threshold\n",
    "    dataloader_data_dir = config.data_dir\n",
    "    distortion = config.distortion\n",
    "    distortion_level = config.distortion_level\n",
    "\n",
    "    #...binerize MNIST images for dataset 1:\n",
    "\n",
    "    transformation_list = [transforms.ToTensor(), transforms.Lambda(lambda x: (x > threshold).float())]\n",
    "\n",
    "    #...define 1-parametric distortions for dataset 0:\n",
    "\n",
    "    distortion_list=[]\n",
    "    \n",
    "    if distortion == 'noise': \n",
    "        distortion_list.append(transforms.ToTensor())\n",
    "        distortion_list.append(transforms.Lambda(lambda x: add_gaussian_noise(x, std=distortion_level)))\n",
    "    \n",
    "    elif distortion == 'swirl': \n",
    "        distortion_list.append(transforms.Lambda(lambda x: apply_swirl(x, strength=distortion_level)))\n",
    "        distortion_list.append(transforms.ToTensor())\n",
    "\n",
    "    elif distortion == 'pixelate': \n",
    "        distortion_list.append(transforms.Lambda(lambda x: apply_coarse_grain(x, p=distortion_level)))\n",
    "        distortion_list.append(transforms.ToTensor())\n",
    "\n",
    "    elif distortion == 'half_mask':\n",
    "        distortion_list.append(transforms.Lambda(lambda x: apply_half_mask(x)))\n",
    "        distortion_list.append(transforms.ToTensor())\n",
    "\n",
    "    elif distortion == 'half_noise':\n",
    "        distortion_list.append(transforms.Lambda(lambda x: apply_half_noise(x, std=distortion_level)))\n",
    "        distortion_list.append(transforms.ToTensor())\n",
    "\n",
    "    distortion_list.append(transforms.Lambda(lambda x: (x > threshold).float()))\n",
    "\n",
    "    #...reshape images accordingly:\n",
    "\n",
    "    if config.flatten:\n",
    "        transformation_list.append(FlattenTransform)\n",
    "        distortion_list.append(FlattenTransform)\n",
    "\n",
    "    if not config.as_image:\n",
    "        transformation_list.append(SqueezeTransform)\n",
    "        distortion_list.append(SqueezeTransform)\n",
    "\n",
    "    if config.unet_resize:\n",
    "        transformation_list.append(transforms.Resize((32, 32)))\n",
    "        distortion_list.append(transforms.Resize((32, 32)))\n",
    "\n",
    "    #...compose relevant transformations:\n",
    "        \n",
    "    distort = transforms.Compose(distortion_list)\n",
    "    transform = transforms.Compose(transformation_list)\n",
    "\n",
    "    # Load MNIST dataset\n",
    "\n",
    "    if data_ == \"mnist\":\n",
    "        train_data_0 = datasets.MNIST(dataloader_data_dir, train=True, download=True, transform=distort)\n",
    "        test_data_0 = datasets.MNIST(dataloader_data_dir, train=False, download=True, transform=distort)\n",
    "        train_data_1 = datasets.MNIST(dataloader_data_dir, train=True, download=True, transform=transform)\n",
    "        test_data_1 = datasets.MNIST(dataloader_data_dir, train=False, download=True, transform=transform)\n",
    "    else:\n",
    "        raise Exception(\"Distortions only implemented for 'mnist' dataset!\")\n",
    "\n",
    "    return (train_data_0, test_data_0), (train_data_1, test_data_1)\n",
    "\n",
    "\n",
    "class DistortedNISTLoaderDataEdge:\n",
    "    def __init__(self, test_dl, train_dl):\n",
    "        self.test_dl = test_dl\n",
    "        self.train_dl = train_dl\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_dl\n",
    "\n",
    "    def test(self):\n",
    "        return self.test_dl\n",
    "\n",
    "\n",
    "class CoupledNISTDataset(Dataset):\n",
    "    def __init__(self, dataset_0, dataset_1):\n",
    "        self.dataset_0 = dataset_0\n",
    "        self.dataset_1 = dataset_1\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.dataset_0), len(self.dataset_1))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_0, _ = self.dataset_0[idx]\n",
    "        img_1, _ = self.dataset_1[idx]\n",
    "        return img_0, img_1 \n",
    "\n",
    "class DistortedNISTLoader:\n",
    "    config: DistortedNISTLoaderConfig\n",
    "    name: str = \"DistortedNISTDataloader\"\n",
    "\n",
    "    def __init__(self, config: DistortedNISTLoaderConfig):\n",
    "        \"\"\"\n",
    "        :param config:\n",
    "        :param device:\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.number_of_spins = self.config.dimensions\n",
    "        data_0, data_1 = get_conditional_data(self.config)\n",
    "        self.create_conditional_dataloaders(data_1, data_0)\n",
    "\n",
    "    def train(self):\n",
    "        return self.train_conditional()\n",
    "\n",
    "    def test(self):\n",
    "        return self.test_conditional()\n",
    "\n",
    "    def train_conditional(self):\n",
    "        for databatch in self.data_train:\n",
    "            yield [databatch[0]],[databatch[1]]\n",
    "\n",
    "    def test_conditional(self):\n",
    "        for databatch in self.data_test:\n",
    "            yield [databatch[0]],[databatch[1]]\n",
    "\n",
    "    def define_sample_sizes(self):\n",
    "        self.training_data_size = self.config.training_size\n",
    "        self.test_data_size = self.config.test_size\n",
    "        self.total_data_size = self.training_data_size + self.test_data_size\n",
    "        self.config.training_proportion = float(self.training_data_size) / self.total_data_size\n",
    "\n",
    "    def create_conditional_dataloaders(self, data_1, data_0):\n",
    "        train_data_0, test_data_0 = data_0\n",
    "        train_data_1, test_data_1 = data_1\n",
    "\n",
    "        #=======================\n",
    "        # INDEPENDENT\n",
    "        #=======================\n",
    "\n",
    "        self.data0_train = DataLoader(train_data_0, batch_size=self.config.batch_size, shuffle=True)\n",
    "        self.data1_train = DataLoader(train_data_1, batch_size=self.config.batch_size, shuffle=True)\n",
    "        self.data0_test = DataLoader(test_data_0, batch_size=self.config.batch_size, shuffle=True)\n",
    "        self.data1_test = DataLoader(test_data_1, batch_size=self.config.batch_size, shuffle=True)\n",
    "        self.data1 = DistortedNISTLoaderDataEdge(self.data1_test, self.data1_train)\n",
    "        self.data0 = DistortedNISTLoaderDataEdge(self.data0_test, self.data0_train)\n",
    "\n",
    "        #=======================\n",
    "        # COUPLED\n",
    "        #=======================\n",
    "\n",
    "        train_ds = CoupledNISTDataset(train_data_0, train_data_1)\n",
    "        test_ds = CoupledNISTDataset(test_data_0, test_data_1)\n",
    "        self.data_train = DataLoader(train_ds, batch_size=self.config.batch_size, shuffle=True)\n",
    "        self.data_test = DataLoader(test_ds, batch_size=self.config.batch_size, shuffle=False)\n",
    "\n",
    "#...type of MNIST distortions\n",
    "\n",
    "def add_gaussian_noise(tensor, mean=0., std=0.4):\n",
    "    \"\"\"Adds Gaussian noise to a tensor.\"\"\"\n",
    "    noise = torch.randn(tensor.size()) * std + mean\n",
    "    return tensor + noise\n",
    "\n",
    "def apply_swirl(image, strength=5, radius=20):\n",
    "    \"\"\"Apply swirl distortion to an image.\"\"\"\n",
    "    image_np = np.array(image)\n",
    "    swirled_image = swirl(image_np, strength=strength, radius=radius, mode='reflect')\n",
    "    return Image.fromarray(swirled_image)\n",
    "\n",
    "def apply_coarse_grain(image, p=0.7):\n",
    "    \"\"\"Coarse grains an image to a lower resolution.\"\"\"\n",
    "    old_size = image.size\n",
    "    if p <= 0: return image  \n",
    "    elif p >= 1: return Image.new('L', image.size, color=0)  # Return a black image\n",
    "    new_size = max(1, int(image.width * (1 - p))), max(1, int(image.height * (1 - p)))\n",
    "    image = image.resize(new_size, Image.BILINEAR)\n",
    "    return image.resize(old_size, Image.NEAREST)  # Resize back to 28x28\n",
    "\n",
    "def apply_half_mask(image):\n",
    "    \"\"\" Masks the first half of the image along its width. \"\"\"\n",
    "    mask_height = int(image.height / 2)\n",
    "    mask_width = image.width\n",
    "    mask_size = (mask_width, mask_height)\n",
    "    mask = Image.new('L', mask_size, color=255) \n",
    "    black_img = Image.new('L', image.size, color=0)\n",
    "    black_img.paste(mask, (0, 0))  \n",
    "    return Image.composite(image, black_img, black_img)\n",
    "\n",
    "def apply_half_noise(image, std=1):\n",
    "    \"\"\" Masks the first half of the image along its width. \"\"\"\n",
    "    mask_height = int(image.height / 2)\n",
    "    mask_width = image.width\n",
    "    mask_size = (mask_width, mask_height)\n",
    "    mask = Image.new('L', mask_size, color=255) \n",
    "    black_img = Image.new('L', image.size, color=0)\n",
    "    black_img.paste(mask, (0, 0))  \n",
    "    return Image.composite(image, black_img, black_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(images, figsize=(4, 4), cmap=None):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, ax in enumerate(axes):\n",
    "        img = images[i].permute(1, 2, 0)\n",
    "        # img = img.squeeze()  # Squeeze the last dimension if it's 1\n",
    "        if cmap is not None: ax.imshow(img, cmap=cmap)\n",
    "        else: ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAACgCAYAAABqgSVVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEs0lEQVR4nO3dzY1bNxQG0BkhRRiuwk0MUsFUORUYasJ771OGXrYBTOWjQIo/T+csjTd4lEJ8uODNpd6P4zjeALjrMnsBAKsTlACBoAQIBCVAICgBAkEJEAhKgEBQAgR/1T74cfl85jr4j5///Prj3/7+/mP4Olpdb19D32eP8qjaPaqiBAgEJUAgKAECQQkQVDdzXs3MhsqOjZvS9wVnoaIECAQlQCAoAQJBCRBo5tyxY0NlptL3db2NXwc8g4oSIBCUAIGgBAgEJUCgmXPHzMmc2nePeK6k5W9hRypKgEBQAgSCEiAQlABBUzPnLL/tssPnaFlj7+dq/9ZkTj+r7dGWxt+OVJQAgaAECAQlQCAoAYKmZs6sg9oRB8mjDs9bJlp6T+ZAyYg9ujoVJUAgKAECQQkQCEqAoPs1ayMaDCMOg0cdOPe+sszB+/7OfmXdjlM9KkqAQFACBIISIBCUAEH3Zk5LQ2ZEM6H2IHlmY6P2PTseitPPqD3aez+2vGMWFSVAICgBAkEJEAhKgKB7M2d1vQ+m7z3XMnHT+7drRvwt/fSe1hqlZd2rT4WpKAECQQkQCEqAQFACBEs1c0Yc3vY+FH9kzbM+30qH4lCy+h5VUQIEghIgEJQAgaAECJZq5pT0bk7MnB4Y0WiZdX0da9j1v/Xq61ZRAgSCEiAQlACBoAQIlm/mnKk5MWuNO3w3/L8drl7zmzkAL0xQAgSCEiAQlADB8s2cklnTLCWP/GZOrdUO6dnbant09cZNiYoSIBCUAIGgBAgEJUBQ3cxZfRpm9fW9vZ2nSbPDd/0KWqd1zrIfR1BRAgSCEiAQlACBoAQItpzMKaltJtQ2IlY7KF+pWbLDlV8810r7cQQVJUAgKAECQQkQCEqAQFACBNVd77N0uXp3x5/R7d3xuy6t+Xobv45X4v80GEdFCRAISoBAUAIEghIgOM0IY0nvH0Ca2bgZcQekeybXsFqTxh5QUQJEghIgEJQAgaAECN6P4zhqHvy4fP7xb6sf/veernnks/VuJK2u9Hkv334PXUNpj65u5r2lr7ZHS663r6rnVJQAgaAECAQlQCAoAYKmyZyVDnRrD6ZHNaBamkY7TuG4Zi3TPNmXihIgEJQAgaAECAQlQLD8NWstTYdRV6X1NuLgXnOA1RuOK1FRAgSCEiAQlACBoAQIlm/m9D5wrn1u10YQa+i9V+zRuVSUAIGgBAgEJUAgKAGCac2c3hM3te+otdqh+KxJiFebwNjJzD36antARQkQCEqAQFACBIISIJjWzGk5DK49xK6dXDDhcN+rHdr3Yk+di4oSIBCUAIGgBAgEJUCw/DVrJbMOyh9pbPSeaNFU2d+IibJW9lmZihIgEJQAgaAECAQlQPB+HMdR8+DH5fPZa+Fkrrevoe+zR3lU7R5VUQIEghIgEJQAgaAECJomc1qmT1quO5s1PbDSWoBxVJQAgaAECAQlQCAoAQKTOXRRanRdvv0eugZ7lEeZzAHoRFACBIISIBCUAMGWv5nT25kmbmZ9ltI7rrenvxaGUFECBIISIBCUAIGgBAiqJ3MAXpWKEiAQlACBoAQIBCVAICgBAkEJEAhKgEBQAgSCEiD4FwtuolplqQbYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from conditional_rate_matching.data.image_dataloader_config import DistortedNISTLoaderConfig\n",
    "\n",
    "data_config = DistortedNISTLoaderConfig(flatten=False, batch_size=1)\n",
    "data_config.distortion = 'noise'\n",
    "data_config.distortion_level = 0.4\n",
    "dataloder = DistortedNISTLoader(data_config)\n",
    "img = next(dataloder.data_train.__iter__())\n",
    "plot_images(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAACgCAYAAABqgSVVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADtUlEQVR4nO3d0W3bSBRA0SRwFakiTQSpYKvcCoI0kSpSRpSP/O1KuJQpUTPDcz4NA6Ls8cVgnkl9vFwulw8A3PTp1RcAMDqhBAhCCRCEEiAIJUAQSoAglABBKAHC29Zv/Prpn2deBwv68fvfQ1/PGuVeW9eoHSVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgvL36AgC+//r5v699+/zl8Ou4xY4SIAglQBBKgCCUAMEw5wSuHZRfM9LhOevauh5HYkcJEIQSIAglQBBKgLDMMGfGA+JbDFXObYa1vHWNzvBetrCjBAhCCRCEEiAIJUCYcpizygHxLXseObX6z2YWfg9rsaMECEIJEIQSIAglQBh+mLPnUHy0O1z2vJdHf6bIaD+bma0+uHn0IHHGtWdHCRCEEiAIJUAQSoAw1DDnjIfiR7znGQ/PR+X39dfqf6v/ZUcJEIQSIAglQBBKgDDUMOfRZjh43zrgedUgiMeZYUhzzUp3x72XHSVAEEqAIJQAQSgBwlDDnBkHFreuzyPQmJHBzXV2lABBKAGCUAIEoQQIQw1zrtlzQDz6IOgeK38eyVk8+nOP9jK42c6OEiAIJUAQSoAglABh+GHOHjPe6XOPsx2oj+DRa+qIId3eNW+d2VECJKEECEIJEIQSIAglQFh66n2EZ0wEV5rMn8ER/11hTbyWHSVAEEqAIJQAQSgBwtLDnCMOwJ/xGm4Zm99Kz1H13Eo7SoAklABBKAGCUAKEpYc5W+25s2KVw2rGsfpzVGdkRwkQhBIgCCVAEEqAcLphztbhy9YD9XsO2Q1+eIVXPgrw2vfN+HdgRwkQhBIgCCVAEEqAcLphzp7D5XsOofcOfva8Nuc12joZ7Xrey44SIAglQBBKgCCUAOF0w5yjeFQW72WdjMeOEiAIJUAQSoAglADBMOfDOo+CgmcwXLKjBEhCCRCEEiAIJUBYepiz5+4YB9jM6JXrduUBqB0lQBBKgCCUAEEoAcLSw5xZrXwoTpvhEX1nW6N2lABBKAGCUAIEoQQIpxvmbD2EPurw/GyH4rzPaOv2bOwoAYJQAgShBAhCCRBON8zZypCFGVm3z2FHCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBwsfL5XJ59UUAjMyOEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIg/AGOnsP0nikNDAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_config = DistortedNISTLoaderConfig(flatten=False, batch_size=1)\n",
    "data_config.distortion = 'swirl'\n",
    "data_config.distortion_level = -4\n",
    "dataloder = DistortedNISTLoader(data_config)\n",
    "img = next(dataloder.data_train.__iter__())\n",
    "plot_images(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1809047/2783328872.py:188: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  image = image.resize(new_size, Image.BILINEAR)\n",
      "/tmp/ipykernel_1809047/2783328872.py:189: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  return image.resize(old_size, Image.NEAREST)  # Resize back to 28x28\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAACgCAYAAABqgSVVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADLUlEQVR4nO3d0W3UQBRA0U2UKqiCJhAVUCUVIJqgCsrA/KNdXS+7a4/H53xHxCtGV0/z4uRtWZblAsBN73s/AMDohBIgCCVAEEqAIJQAQSgBglACBKEECB9rv/DL+7dXPgcT+vnn+6bfzxnlXmvPqIkSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAcLH3g/A//vx+9eqr/v66fNLnwPuccRza6IECEIJEIQSIAglQLDMAZ5i7ZLmkX9vrwWPiRIgCCVAEEqAIJQAwTJnQ8++7H729x3pTQjGsde5HYmJEiAIJUAQSoAglADBMgdOaoslzSMLwpGWSCZKgCCUAEEoAYJQAgTLnBtecZG815svI12K81oznduRmCgBglACBKEECEIJECxz4ABmX9KMvnA0UQIEoQQIQgkQhBIgTLPMefZl8EgX3Y+a6bOcwSNn+Qj/10f8G04mSoAglABBKAGCUAKEaZY5MLrZlzQzM1ECBKEECEIJEIQSIAy/zPHGzW1HfMPhLEb/tWFbmeWMmigBglACBKEECEIJEIQSIAy/9YbRnfEnM872OqaJEiAIJUAQSoAglABht2WOC/Db1n6WI3zm2ZxtiXG5nPMz/8tECRCEEiAIJUAQSoDgzRy4YZYlxit+N+ZIn28LJkqAIJQAQSgBglAChOGXOXtdGrsAZ62Zzug1zq2JEiAJJUAQSoAglABh+GUOzGKr5ctaljTrmSgBglACBKEECEIJEHZb5qy9SN7rb+u46ObaGbh2HrdY0jiP+zJRAgShBAhCCRCEEiB4MwfuYKlyTiZKgCCUAEEoAYJQAoThlzkuz4G9mSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSILwty7Ls/RAAIzNRAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAKEv07Ce+yCjhvNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_config = DistortedNISTLoaderConfig(flatten=False, batch_size=1)\n",
    "data_config.distortion = 'pixelate'\n",
    "data_config.distortion_level = 0.5\n",
    "dataloder = DistortedNISTLoader(data_config)\n",
    "img = next(dataloder.data_train.__iter__())\n",
    "plot_images(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAACgCAYAAABqgSVVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADRElEQVR4nO3d0W3UQBRA0SSiCqqgCUQFVEkFiCaogjJwGnB0vbLXHk/O+Y60+zG5epone1+XZVleAPjQ29VfAGB0QgkQhBIgCCVAEEqAIJQAQSgBglAChC9b//D7289nfg8m9Of/r1M/zxnlUVvPqIkSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAsPk3c0b3+9/fSz73x9dvl3wu9+OM3peJEiAIJUAQSoAglADhlsucqy7F13z0XVygf27O6FxMlABBKAGCUAIEoQQIwy9z9lyKH31Z/ch3Wftbl+dzckbnZ6IECEIJEIQSIAglQBh+mbPVGZfQa58x0hMYjM0ZvS8TJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAmObJnDM88oSD11VxBWf0OUyUAEEoAYJQAgShBAjDL3POeG2U11CxhzM6PxMlQBBKgCCUAEEoAcLwy5w1W58ocAHOVZzRuZgoAYJQAgShBAhCCRBuucy5g6Mv6b0Si6M5o9uZKAGCUAIEoQQIQgkQpl7mXHm5fMZrtma+PP8snNF7MFECBKEECEIJEIQSIEy9zLnSLJfYzOvoM7q2zNm6MBr9/8VECRCEEiAIJUAQSoAglADB1hs4xNrmeuvWe/THH02UAEEoAYJQAgShBAiWOcDT7FnwjMRECRCEEiAIJUAQSoBgmQOcauuCZ6SndUyUAEEoAYJQAgShBAiWOcCQvGYN4EaEEiAIJUAQSoBgmQM7bX1t2EjLCR5jogQIQgkQhBIgCCVAsMyBk4z02rAr+c0cgAkJJUAQSoAglADBMgd22vobMGv2LDauXAQdvZAZfallogQIQgkQhBIgCCVAsMyBJ9i6nNizFLnjEy4vL+MvbtaYKAGCUAIEoQQIQgkQLHPgQkcvNq5c8NxxSbOViRIgCCVAEEqAIJQAwTIHJjLzQuVKJkqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAHC67Isy9VfAmBkJkqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgPAOWSOS0ItLfHoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_config = DistortedNISTLoaderConfig(flatten=False, batch_size=1)\n",
    "data_config.distortion = 'half_mask'\n",
    "data_config.distortion_level = 1\n",
    "dataloder = DistortedNISTLoader(data_config)\n",
    "img = next(dataloder.data_train.__iter__())\n",
    "plot_images(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conditional_rate_matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
